{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\Ravikanth\\\\Analytics Vidya\\\\1.Loan Prediction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_u6lujuX_CVtuZ9i.csv')\n",
    "test = pd.read_csv('test_Y3wMUE5_7gLdaTN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape: (614, 13)   Test Shape: (367, 12)\n"
     ]
    }
   ],
   "source": [
    "print('Train Shape: {}   Test Shape: {}' .format(train.shape , test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Y    68.729642\n",
       "N    31.270358\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(train['Loan_Status'].values)/len(train['Loan_Status'])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lets Do some data Preprocessing . We will cover following taks:\\n1. Check Data types such as Numerics , Date , Strings , Categories\\n2. Do Label encoding for object columns which have two categories\\n3. DO One Hot Encoding for object columns which have more than 2 categories\\n4. Do Imputation for missing values\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''This is a perfect case of imbalanced class'''\n",
    "'''Lets Do some data Preprocessing . We will cover following taks:\n",
    "1. Check Data types such as Numerics , Date , Strings , Categories\n",
    "2. Do Label encoding for object columns which have two categories\n",
    "3. DO One Hot Encoding for object columns which have more than 2 categories\n",
    "4. Do Imputation for missing values\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def miss_val(df):\n",
    "    miss_values =  df.isnull().sum()\n",
    "    miss_values_percent = df.isnull().sum()/len(df)*100\n",
    "    miss_values_table = pd.concat([miss_values,miss_values_percent] , axis =1)\n",
    "    miss_values_table_ren = miss_values_table.rename(columns ={ 0: 'Missing Value' , 1:'Percent'})\n",
    "    return miss_values_table_ren "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Value</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Loan_ID</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>13</td>\n",
       "      <td>2.117264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Married</th>\n",
       "      <td>3</td>\n",
       "      <td>0.488599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dependents</th>\n",
       "      <td>15</td>\n",
       "      <td>2.442997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Self_Employed</th>\n",
       "      <td>32</td>\n",
       "      <td>5.211726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LoanAmount</th>\n",
       "      <td>22</td>\n",
       "      <td>3.583062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <td>14</td>\n",
       "      <td>2.280130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credit_History</th>\n",
       "      <td>50</td>\n",
       "      <td>8.143322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Property_Area</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loan_Status</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Missing Value   Percent\n",
       "Loan_ID                        0  0.000000\n",
       "Gender                        13  2.117264\n",
       "Married                        3  0.488599\n",
       "Dependents                    15  2.442997\n",
       "Education                      0  0.000000\n",
       "Self_Employed                 32  5.211726\n",
       "ApplicantIncome                0  0.000000\n",
       "CoapplicantIncome              0  0.000000\n",
       "LoanAmount                    22  3.583062\n",
       "Loan_Amount_Term              14  2.280130\n",
       "Credit_History                50  8.143322\n",
       "Property_Area                  0  0.000000\n",
       "Loan_Status                    0  0.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "miss_val(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loan_ID          614\n",
       "Gender             2\n",
       "Married            2\n",
       "Dependents         4\n",
       "Education          2\n",
       "Self_Employed      2\n",
       "Property_Area      3\n",
       "Loan_Status        2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.select_dtypes('object').apply(pd.Series.nunique, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As you can see most of the object columns have 2 categories. So lets do label encoding to these object columns'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''As you can see most of the object columns have 2 categories. So lets do label encoding to these object columns'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets do label encoding manually for train data first. Then we wil do the same for test data as well\n",
    "train['Gender'] =  le.fit_transform(train['Gender'].astype(str))\n",
    "train['Married'] =  le.fit_transform(train['Married'].astype(str))\n",
    "train['Education'] =  le.fit_transform(train['Education'].astype(str))\n",
    "train['Self_Employed'] =  le.fit_transform(train['Self_Employed'].astype(str))\n",
    "mapper = { 'Y' : 1 , 'N' : 0}\n",
    "train['Loan_Status'] = train['Loan_Status'].map(mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets do label encoding manually for test data first.\n",
    "test['Gender'] =  le.fit_transform(test['Gender'].astype(str))\n",
    "test['Married'] =  le.fit_transform(test['Married'].astype(str))\n",
    "test['Education'] =  le.fit_transform(test['Education'].astype(str))\n",
    "test['Self_Employed'] =  le.fit_transform(test['Self_Employed'].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(614, 13)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now lets do OHE (One hot encoding) for columns with more than 2 categories. Lets do it using getdummies function of Pandas\n",
    "#Before doing OHE lets check the shape \n",
    "train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_label = train['Loan_Status']\n",
    "train_dm = pd.get_dummies(train.drop(columns=['Loan_ID','Loan_Status']))\n",
    "train_dm['Loan_Status'] = target_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(614, 17)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(367, 16)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dm = pd.get_dummies(test.drop(columns='Loan_ID'))\n",
    "test_dm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(529, 17)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dm.dropna(axis = 0,inplace=True)\n",
    "train_dm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Value</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Married</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Self_Employed</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LoanAmount</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credit_History</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dependents_0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dependents_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dependents_2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dependents_3+</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Property_Area_Rural</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Property_Area_Semiurban</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Property_Area_Urban</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loan_Status</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Missing Value  Percent\n",
       "Gender                               0      0.0\n",
       "Married                              0      0.0\n",
       "Education                            0      0.0\n",
       "Self_Employed                        0      0.0\n",
       "ApplicantIncome                      0      0.0\n",
       "CoapplicantIncome                    0      0.0\n",
       "LoanAmount                           0      0.0\n",
       "Loan_Amount_Term                     0      0.0\n",
       "Credit_History                       0      0.0\n",
       "Dependents_0                         0      0.0\n",
       "Dependents_1                         0      0.0\n",
       "Dependents_2                         0      0.0\n",
       "Dependents_3+                        0      0.0\n",
       "Property_Area_Rural                  0      0.0\n",
       "Property_Area_Semiurban              0      0.0\n",
       "Property_Area_Urban                  0      0.0\n",
       "Loan_Status                          0      0.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "miss_val(train_dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''As you can see there is no missing value in train data. Lets do similar excersize for test data '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Value</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Married</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Self_Employed</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LoanAmount</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credit_History</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dependents_0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dependents_1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dependents_2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dependents_3+</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Property_Area_Rural</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Property_Area_Semiurban</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Property_Area_Urban</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Missing Value  Percent\n",
       "Gender                               0      0.0\n",
       "Married                              0      0.0\n",
       "Education                            0      0.0\n",
       "Self_Employed                        0      0.0\n",
       "ApplicantIncome                      0      0.0\n",
       "CoapplicantIncome                    0      0.0\n",
       "LoanAmount                           0      0.0\n",
       "Loan_Amount_Term                     0      0.0\n",
       "Credit_History                       0      0.0\n",
       "Dependents_0                         0      0.0\n",
       "Dependents_1                         0      0.0\n",
       "Dependents_2                         0      0.0\n",
       "Dependents_3+                        0      0.0\n",
       "Property_Area_Rural                  0      0.0\n",
       "Property_Area_Semiurban              0      0.0\n",
       "Property_Area_Urban                  0      0.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dm.fillna(test_dm.median(), inplace= True)\n",
    "test_dm.shape\n",
    "miss_val(test_dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Now we are good to go for building model. Lets try first with logistic Regression , then with SVM, DTree, Random Forest'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Now we are good to go for building model. Lets try first with logistic Regression , then with SVM, DTree, Random Forest'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train , x_test , y_train , y_test = train_test_split(train_dm.iloc[:,:-1] , train_dm['Loan_Status'] , test_size = 0.2 , random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "svm = SVC(C=1.0)\n",
    "dtree = DecisionTreeClassifier(criterion='gini' , random_state= 100)\n",
    "rf = RandomForestClassifier(random_state=100)\n",
    "mlp =MLPClassifier(max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Logistic Regression  \n",
      " Accuracy: 0.7735849056603774 \n",
      "Using K Nearest Neighbours  \n",
      " Accuracy: 0.7169811320754716 \n",
      "Using Support Vector Machines  \n",
      " Accuracy: 0.6698113207547169 \n",
      "Using Decision Trees  \n",
      " Accuracy: 0.7169811320754716 \n",
      "Using Random Forest  \n",
      " Accuracy: 0.7358490566037735 \n",
      "Using MLP  \n",
      " Accuracy: 0.5377358490566038 \n"
     ]
    }
   ],
   "source": [
    "classifiers = [lr,knn,svm,dtree,rf,mlp]\n",
    "Lables = ['Logistic Regression' , 'K Nearest Neighbours','Support Vector Machines', 'Decision Trees', 'Random Forest','MLP']\n",
    "for clf , label in zip(classifiers , Lables):\n",
    "    clf.fit(x_train,y_train)\n",
    "    score = clf.score(x_test,y_test)\n",
    "    print('Using {}  \\n Accuracy: {} ' .format(label, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As you can see the Accuracy is very bad except for Logistic Regression. Now lets try different methods to imporve the score'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''As you can see the Accuracy is very bad except for Logistic Regression. Now lets try different methods to imporve the score'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'First we we will do scaling'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''First we we will do scaling'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "sc.fit(x_train)\n",
    "x_train_sc = sc.transform(x_train)\n",
    "x_test_sc = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Logistic Regression  \n",
      " Accuracy: 0.7830188679245284 \n",
      "Using K Nearest Neighbours  \n",
      " Accuracy: 0.7452830188679245 \n",
      "Using Support Vector Machines  \n",
      " Accuracy: 0.7830188679245284 \n",
      "Using Decision Trees  \n",
      " Accuracy: 0.7169811320754716 \n",
      "Using Random Forest  \n",
      " Accuracy: 0.7358490566037735 \n"
     ]
    }
   ],
   "source": [
    "classifiers = [lr,knn,svm,dtree,rf]\n",
    "Lables = ['Logistic Regression' , 'K Nearest Neighbours','Support Vector Machines', 'Decision Trees', 'Random Forest']\n",
    "for clf , label in zip(classifiers , Lables):\n",
    "    clf.fit(x_train_sc,y_train)\n",
    "    score = clf.score(x_test_sc,y_test)\n",
    "    print('Using {}  \\n Accuracy: {} ' .format(label, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As you can see , by using standardization the accuracy for SCV increased drastically. Now lets focus on creating polynomials\\nand decomposition'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''As you can see , by using standardization the accuracy for SCV increased drastically. Now lets focus on creating polynomials\n",
    "and decomposition'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train['Loan_Status'] = target_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loan_Status                1.000000\n",
       "Credit_History             0.570940\n",
       "Property_Area_Semiurban    0.145525\n",
       "Married                    0.104273\n",
       "Dependents_2               0.092939\n",
       "Gender                     0.064063\n",
       "Self_Employed              0.047978\n",
       "Dependents_3+              0.001829\n",
       "Dependents_1              -0.002913\n",
       "CoapplicantIncome         -0.006251\n",
       "ApplicantIncome           -0.023401\n",
       "Property_Area_Urban       -0.037390\n",
       "Loan_Amount_Term          -0.041534\n",
       "Dependents_0              -0.042372\n",
       "LoanAmount                -0.067185\n",
       "Education                 -0.080639\n",
       "Property_Area_Rural       -0.118451\n",
       "Name: Loan_Status, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.corr()['Loan_Status'].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "polynomials = PolynomialFeatures(degree=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape : (423, 153)  X_test Shape: (106, 153)\n"
     ]
    }
   ],
   "source": [
    "x_train_sc = polynomials.fit_transform(x_train_sc)\n",
    "x_test_sc = polynomials.fit_transform(x_test_sc)\n",
    "print('X_train shape : {}  X_test Shape: {}' .format(x_train_sc.shape , x_test_sc.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Logistic Regression  \n",
      " Accuracy: 0.7264150943396226 \n",
      "Using K Nearest Neighbours  \n",
      " Accuracy: 0.7169811320754716 \n",
      "Using Support Vector Machines  \n",
      " Accuracy: 0.7735849056603774 \n",
      "Using Decision Trees  \n",
      " Accuracy: 0.7358490566037735 \n",
      "Using Random Forest  \n",
      " Accuracy: 0.7358490566037735 \n"
     ]
    }
   ],
   "source": [
    "classifiers = [lr,knn,svm,dtree,rf]\n",
    "Lables = ['Logistic Regression' , 'K Nearest Neighbours','Support Vector Machines', 'Decision Trees', 'Random Forest']\n",
    "for clf , label in zip(classifiers , Lables):\n",
    "    clf.fit(x_train_sc,y_train)\n",
    "    score = clf.score(x_test_sc,y_test)\n",
    "    print('Using {}  \\n Accuracy: {} ' .format(label, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'After creating polynomial , accuracy decreased.So lets do decomposition'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''After creating polynomial , accuracy decreased.So lets do decomposition'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=5, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999999960942324"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_pca = pca.fit_transform(x_train)\n",
    "x_test_pca = pca.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Logistic Regression  \n",
      " Accuracy: 0.660377358490566 \n",
      "Using K Nearest Neighbours  \n",
      " Accuracy: 0.6509433962264151 \n",
      "Using Support Vector Machines  \n",
      " Accuracy: 0.6698113207547169 \n",
      "Using Decision Trees  \n",
      " Accuracy: 0.5849056603773585 \n",
      "Using Random Forest  \n",
      " Accuracy: 0.6320754716981132 \n"
     ]
    }
   ],
   "source": [
    "classifiers = [lr,knn,svm,dtree,rf]\n",
    "Lables = ['Logistic Regression' , 'K Nearest Neighbours','Support Vector Machines', 'Decision Trees', 'Random Forest']\n",
    "for clf , label in zip(classifiers , Lables):\n",
    "    clf.fit(x_train_pca,y_train)\n",
    "    score = clf.score(x_test_pca,y_test)\n",
    "    print('Using {}  \\n Accuracy: {} ' .format(label, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Surprisingly the accuracy dropped after doing PCA. Finally lets try XGBOOST and LGBM'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgbm\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = xgb.XGBClassifier(n_estimators=100 ,reg_alpha=0 ,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic',\n",
       "       random_state=10, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf.fit(x_train_sc , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Ravikanth\\K\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7641509433962265"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf.score(x_test_sc,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Ravikanth\\K\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7452830188679245"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_clf = lgbm.LGBMClassifier()\n",
    "lgbm_clf.fit(x_train_sc , y_train)\n",
    "lgbm_clf.score(x_test_sc,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(C=1)\n",
    "lr.fit(train_dm.iloc[:,:-1] , train_dm['Loan_Status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Ravikanth\\K\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "sc = StandardScaler()\n",
    "X_tr = train_dm.iloc[:,:-1]\n",
    "Y_tr = train_dm['Loan_Status']\n",
    "sc.fit(X_tr)\n",
    "X_tr_sc = sc.transform(X_tr)\n",
    "X_te_sc =  sc.transform(test_dm)\n",
    "xgb_clf.fit(X_tr_sc , Y_tr)\n",
    "pred_loan_status=lgbm_clf.predict(X_te_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Ravikanth\\K\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "sc = StandardScaler()\n",
    "X_tr = train_dm.iloc[:,:-1]\n",
    "Y_tr = train_dm['Loan_Status']\n",
    "sc.fit(X_tr)\n",
    "X_tr_sc = sc.transform(X_tr)\n",
    "X_te_sc =  sc.transform(test_dm)\n",
    "mlp =MLPClassifier(max_iter=500)\n",
    "mlp.fit(X_tr_sc , Y_tr)\n",
    "pred_loan_status=mlp.predict(X_te_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_1 = pd.DataFrame(test['Loan_ID'] , columns=['Loan_ID','Loan_Status'])\n",
    "submission_1['Loan_Status'] = pred_loan_status\n",
    "mapper = { 1 : 'Y' , 0 : 'N'}\n",
    "submission_1['Loan_Status'] = submission_1['Loan_Status'].map(mapper)\n",
    "submission_1.to_csv('Submission_mlp.csv' , index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Now lets try stacking'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Stacking(model,train,y,test,n_fold):\n",
    "    folds=StratifiedKFold(n_splits=n_fold,random_state=1)\n",
    "    test_pred=np.empty((test.shape[0],1),float)\n",
    "    train_pred=np.empty((0,1),float)\n",
    "    for train_indices,val_indices in folds.split(train,y.values):\n",
    "        x_train,x_val=train.iloc[train_indices],train.iloc[val_indices]\n",
    "        y_train,y_val=y.iloc[train_indices],y.iloc[val_indices]\n",
    "        model.fit(X=x_train,y=y_train)\n",
    "        train_pred=np.append(train_pred,model.predict(x_val))\n",
    "    model.fit(train,y)\n",
    "    test_pred=model.predict(test)\n",
    "    return test_pred ,train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 =LogisticRegression(random_state=100)\n",
    "test_pred1 ,train_pred1=Stacking(model=model1,n_fold=10, train=train_dm.iloc[:,:-1],y=train_dm['Loan_Status'] ,test=test_dm)\n",
    "train_pred1=pd.DataFrame(train_pred1 , columns=['LR'])\n",
    "test_pred1=pd.DataFrame(test_pred1, columns=['LR'])\n",
    "                        \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = DecisionTreeClassifier()\n",
    "test_pred2 ,train_pred2=Stacking(model=model2,n_fold=10, train=train_dm.iloc[:,:-1],y=train_dm['Loan_Status'] ,test=test_dm)\n",
    "train_pred2=pd.DataFrame(train_pred2, columns=['DT'])\n",
    "test_pred2=pd.DataFrame(test_pred2, columns=['DT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = KNeighborsClassifier()\n",
    "test_pred3 ,train_pred3=Stacking(model=model3,n_fold=10, train=train_dm.iloc[:,:-1],y=train_dm['Loan_Status'] ,test=test_dm)\n",
    "train_pred3=pd.DataFrame(train_pred3, columns=['KNN'])\n",
    "test_pred3=pd.DataFrame(test_pred3, columns=['KNN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train_pred1,train_pred2,train_pred3], axis=1)\n",
    "df_test = pd.concat([test_pred1,test_pred2,test_pred3], axis=1)\n",
    "\n",
    "model = LogisticRegression(C = 1, penalty='l2',random_state=100)\n",
    "#model = SVC()\n",
    "model.fit(df,train_dm['Loan_Status'])\n",
    "model.score(df, train_dm['Loan_Status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_loan_status = model.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_2 = pd.DataFrame(test['Loan_ID'] , columns=['Loan_ID','Loan_Status'])\n",
    "submission_2['Loan_Status'] = pred_loan_status\n",
    "mapper = { 1 : 'Y' , 0 : 'N'}\n",
    "submission_2['Loan_Status'] = submission_2['Loan_Status'].map(mapper)\n",
    "submission_2.to_csv('Submission_5.csv' , index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlxtend\n",
    "from mlxtend.classifier import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = KNeighborsClassifier(n_neighbors=1)\n",
    "clf2 = RandomForestClassifier(random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "lr = LogisticRegression(penalty='l1')\n",
    "sclf = StackingClassifier(classifiers=[clf1, clf2, clf3], \n",
    "                          meta_classifier=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sclf.fit(train_dm.iloc[:,:-1],train_dm['Loan_Status'])\n",
    "sclf.score(train_dm.iloc[:,:-1], train_dm['Loan_Status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_loan_status = sclf.predict(test_dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_3 = pd.DataFrame(test['Loan_ID'] , columns=['Loan_ID','Loan_Status'])\n",
    "submission_3['Loan_Status'] = pred_loan_status\n",
    "mapper = { 1 : 'Y' , 0 : 'N'}\n",
    "submission_3['Loan_Status'] = submission_3['Loan_Status'].map(mapper)\n",
    "submission_3.to_csv('Submission_6.csv' , index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
